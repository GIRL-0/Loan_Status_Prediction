{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6573484-e974-433b-a458-3d65210e4bfe",
   "metadata": {},
   "source": [
    "# 대출 승인 여부 이진 분류 모델링\n",
    "- Tab Transformer 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fccaef-28c4-4df4-a3e3-34168f6bef60",
   "metadata": {},
   "source": [
    "## 패키지 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68c516f-b4ec-473d-8f6d-0a62c4a2dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd80916-b2a4-42cf-8684-64399885fa86",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "dad9da1d-a2f8-40a2-a4e0-7b7933c32201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508</td>\n",
       "      <td>128</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358</td>\n",
       "      <td>120</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196</td>\n",
       "      <td>267</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married  Dependents     Education Self_Employed  ApplicantIncome  \\\n",
       "0   Male     Yes           1      Graduate            No             4583   \n",
       "1   Male     Yes           0      Graduate           Yes             3000   \n",
       "2   Male     Yes           0  Not Graduate            No             2583   \n",
       "3   Male      No           0      Graduate            No             6000   \n",
       "4   Male     Yes           2      Graduate           Yes             5417   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0               1508         128               360               1   \n",
       "1                  0          66               360               1   \n",
       "2               2358         120               360               1   \n",
       "3                  0         141               360               1   \n",
       "4               4196         267               360               1   \n",
       "\n",
       "  Property_Area Loan_Status  \n",
       "0         Rural           N  \n",
       "1         Urban           Y  \n",
       "2         Urban           Y  \n",
       "3         Urban           Y  \n",
       "4         Urban           Y  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d0679-ca8a-4d98-86bc-88521063b6e3",
   "metadata": {},
   "source": [
    "## Y 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "66ddf684-4384-4043-8fa0-a40e20f42340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_Status\n",
       "Y    411\n",
       "N    181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd9f5e-bd19-4cde-9646-2f7e69e2dd85",
   "metadata": {},
   "source": [
    "- 클래스 간 불균형 존재\n",
    "- Resampling 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76270193-e05e-4980-9db7-2bcc35886cd0",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f320d2-839c-4d26-acae-9b085d2ea90d",
   "metadata": {},
   "source": [
    "### 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ef5e0007-ee47-4ec4-8bd9-9f338800acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 인코딩\n",
    "\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "710f59ba-2384-4c16-95c8-06a8986f35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Loan_Status', axis=1).values\n",
    "y = df['Loan_Status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fd3e1cd4-271c-4a09-8cc1-69d84041e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d933e8ef-7523-444d-9a10-9b2744247222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 불균형 해결 -> SMOTE 적용\n",
    "# Upsampling\n",
    "smote = SMOTE()#random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e5fa444c-2b2a-4240-bdcd-ae35ed55d0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    328\n",
       "1    328\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc467ace-3e0d-4c1e-a559-67c347dd5a38",
   "metadata": {},
   "source": [
    "- 클래스 불균형 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4c99901d-b68f-426e-9054-bb4534c1d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b4b11a19-3677-48df-8435-82ba2c6b1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입 Tensor로 변경\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a11c0-c0a9-4c44-8e2a-3b906794109b",
   "metadata": {},
   "source": [
    "### 모델 정의\n",
    "- Tab Transformer 사용\n",
    "- https://github.com/lucidrains/tab-transformer-pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b372df7c-1152-456b-835b-e94411ee1844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tab-transformer-pytorch\n",
      "  Downloading tab_transformer_pytorch-0.3.0-py3-none-any.whl.metadata (690 bytes)\n",
      "Collecting einops>=0.3 (from tab-transformer-pytorch)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: torch>=1.6 in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from tab-transformer-pytorch) (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from torch>=1.6->tab-transformer-pytorch) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6->tab-transformer-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\campus4d023\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6->tab-transformer-pytorch) (1.3.0)\n",
      "Downloading tab_transformer_pytorch-0.3.0-py3-none-any.whl (6.9 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.2/43.2 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: einops, tab-transformer-pytorch\n",
      "Successfully installed einops-0.8.0 tab-transformer-pytorch-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tab-transformer-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "219555f9-a8b6-4e81-95ec-9dd5814ec68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab_transformer_pytorch import TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a1cb898f-b831-45bb-ba93-d979d0972d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabTransformer(\n",
    "    categories=[],\n",
    "    num_continuous=X_train_tensor.shape[1],  # 연속형 변수의 개수\n",
    "    dim=64,  # 모델 차원\n",
    "    dim_out=1,  # 이진 분류 출력\n",
    "    depth=10,  # 모델 깊이\n",
    "    heads=16,  # 멀티헤드 어텐션 헤드 수\n",
    "    attn_dropout=0.1,  # 어텐션 드롭아웃\n",
    "    ff_dropout=0.1,  # 피드포워드 드롭아웃\n",
    "    mlp_hidden_mults=(4, 8, 16, 4, 2),  # MLP의 히든 레이어 크기 비율\n",
    "    mlp_act=nn.ReLU(),  # MLP의 활성화 함수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d54eb049-0d4e-4281-905b-a7472a47e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e976ec8b-4651-46a8-9563-90e0d6ed620e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Loss: 0.6504\n",
      "Epoch 200/500, Loss: 0.5873\n",
      "Epoch 300/500, Loss: 0.5176\n",
      "Epoch 400/500, Loss: 0.4513\n",
      "Epoch 500/500, Loss: 0.3703\n",
      "Valid Accuracy: 0.7731\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 및 손실 계산\n",
    "    # model(범주형, 수치형) 각 type별로 따로 넣어야함\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_train_tensor)  # 범주형 변수가 없으므로 비어있는 텐서를 줘야함.\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    # 역전파 및 최적화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0 :\n",
    "      print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_test_tensor)\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "\n",
    "    accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
    "    print(f'Valid Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a16a6e2d-3680-4db3-bcce-f52374e51689",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabTransformer(\n",
    "    categories=[],\n",
    "    num_continuous=X_train_tensor.shape[1],  # 연속형 변수의 개수\n",
    "    dim=64,  # 모델 차원\n",
    "    dim_out=1,  # 이진 분류 출력\n",
    "    depth=10,  # 모델 깊이\n",
    "    heads=20,  # 멀티헤드 어텐션 헤드 수\n",
    "    attn_dropout=0.1,  # 어텐션 드롭아웃\n",
    "    ff_dropout=0.1,  # 피드포워드 드롭아웃\n",
    "    mlp_hidden_mults=(4, 8, 16, 2),  # MLP의 히든 레이어 크기 비율\n",
    "    mlp_act=nn.ReLU(),  # MLP의 활성화 함수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e2cfd6b9-701b-4221-82ba-f221c8bf3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "567651c9-767f-4ed1-b9da-2465f83120f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Loss: 0.6116\n",
      "Epoch 200/500, Loss: 0.5636\n",
      "Epoch 300/500, Loss: 0.4913\n",
      "Epoch 400/500, Loss: 0.4164\n",
      "Epoch 500/500, Loss: 0.3509\n",
      "Valid Accuracy: 0.7815\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 및 손실 계산\n",
    "    # model(범주형, 수치형) 각 type별로 따로 넣어야함\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_train_tensor)  # 범주형 변수가 없으므로 비어있는 텐서를 줘야함.\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    # 역전파 및 최적화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0 :\n",
    "      print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_test_tensor)\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "\n",
    "    accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
    "    print(f'Valid Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3447fbe3-11b2-41de-9492-ea5070c7cf80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500, Loss: 0.6798\n",
      "Epoch 20/500, Loss: 0.6756\n",
      "Epoch 30/500, Loss: 0.6704\n",
      "Epoch 40/500, Loss: 0.6633\n",
      "Epoch 50/500, Loss: 0.6544\n",
      "Epoch 60/500, Loss: 0.6438\n",
      "Epoch 70/500, Loss: 0.6325\n",
      "Epoch 80/500, Loss: 0.6212\n",
      "Epoch 90/500, Loss: 0.6115\n",
      "Epoch 100/500, Loss: 0.6043\n",
      "Epoch 110/500, Loss: 0.5995\n",
      "Epoch 120/500, Loss: 0.5956\n",
      "Epoch 130/500, Loss: 0.5919\n",
      "Epoch 140/500, Loss: 0.5880\n",
      "Epoch 150/500, Loss: 0.5840\n",
      "Epoch 160/500, Loss: 0.5798\n",
      "Epoch 170/500, Loss: 0.5755\n",
      "Epoch 180/500, Loss: 0.5710\n",
      "Epoch 190/500, Loss: 0.5662\n",
      "Epoch 200/500, Loss: 0.5612\n",
      "Epoch 210/500, Loss: 0.5559\n",
      "Epoch 220/500, Loss: 0.5504\n",
      "Epoch 230/500, Loss: 0.5447\n",
      "Epoch 240/500, Loss: 0.5389\n",
      "Epoch 250/500, Loss: 0.5332\n",
      "Epoch 260/500, Loss: 0.5277\n",
      "Epoch 270/500, Loss: 0.5224\n",
      "Epoch 280/500, Loss: 0.5173\n",
      "Epoch 290/500, Loss: 0.5122\n",
      "Epoch 300/500, Loss: 0.5071\n",
      "Epoch 310/500, Loss: 0.5018\n",
      "Epoch 320/500, Loss: 0.4964\n",
      "Epoch 330/500, Loss: 0.4909\n",
      "Epoch 340/500, Loss: 0.4852\n",
      "Epoch 350/500, Loss: 0.4792\n",
      "Epoch 360/500, Loss: 0.4729\n",
      "Epoch 370/500, Loss: 0.4664\n",
      "Epoch 380/500, Loss: 0.4595\n",
      "Epoch 390/500, Loss: 0.4524\n",
      "Epoch 400/500, Loss: 0.4452\n",
      "Epoch 410/500, Loss: 0.4378\n",
      "Epoch 420/500, Loss: 0.4302\n",
      "Epoch 430/500, Loss: 0.4225\n",
      "Epoch 440/500, Loss: 0.4147\n",
      "Epoch 450/500, Loss: 0.4069\n",
      "Epoch 460/500, Loss: 0.3992\n",
      "Epoch 470/500, Loss: 0.3915\n",
      "Epoch 480/500, Loss: 0.3839\n",
      "Epoch 490/500, Loss: 0.3763\n",
      "Epoch 500/500, Loss: 0.3688\n",
      "Valid Accuracy: 0.7899\n"
     ]
    }
   ],
   "source": [
    "model = TabTransformer(\n",
    "    categories=[],\n",
    "    num_continuous=X_train_tensor.shape[1],  # 연속형 변수의 개수\n",
    "    dim=64,  # 모델 차원\n",
    "    dim_out=1,  # 이진 분류 출력\n",
    "    depth=16,  # 모델 깊이\n",
    "    heads=32,  # 멀티헤드 어텐션 헤드 수\n",
    "    attn_dropout=0.1,  # 어텐션 드롭아웃\n",
    "    ff_dropout=0.1,  # 피드포워드 드롭아웃\n",
    "    mlp_hidden_mults=(4, 8, 16, 2),  # MLP의 히든 레이어 크기 비율\n",
    "    mlp_act=nn.ReLU(),  # MLP의 활성화 함수\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 및 손실 계산\n",
    "    # model(범주형, 수치형) 각 type별로 따로 넣어야함\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_train_tensor)  # 범주형 변수가 없으므로 비어있는 텐서를 줘야함.\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    # 역전파 및 최적화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0 :\n",
    "      print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_test_tensor)\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "\n",
    "    accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
    "    print(f'Valid Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "623502c7-fe77-4a8f-8e4d-9d3ee5f8e89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Loss: 0.6203\n",
      "Epoch 200/500, Loss: 0.5740\n",
      "Epoch 300/500, Loss: 0.5309\n",
      "Epoch 400/500, Loss: 0.4914\n",
      "Epoch 500/500, Loss: 0.4610\n",
      "Valid Accuracy: 0.8067\n"
     ]
    }
   ],
   "source": [
    "model = TabTransformer(\n",
    "    categories=[],\n",
    "    num_continuous=X_train_tensor.shape[1],  # 연속형 변수의 개수\n",
    "    dim=64,  # 모델 차원\n",
    "    dim_out=1,  # 이진 분류 출력\n",
    "    depth=16,  # 모델 깊이\n",
    "    heads=64,  # 멀티헤드 어텐션 헤드 수\n",
    "    attn_dropout=0.1,  # 어텐션 드롭아웃\n",
    "    ff_dropout=0.1,  # 피드포워드 드롭아웃\n",
    "    mlp_hidden_mults=(8, 4,2),  # MLP의 히든 레이어 크기 비율\n",
    "    mlp_act=nn.ReLU(),  # MLP의 활성화 함수\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay = 0.001)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 예측 및 손실 계산\n",
    "    # model(범주형, 수치형) 각 type별로 따로 넣어야함\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_train_tensor)  # 범주형 변수가 없으므로 비어있는 텐서를 줘야함.\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    # 역전파 및 최적화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0 :\n",
    "      print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_test_tensor)\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    y_pred_class = (y_pred > 0.5).float()\n",
    "\n",
    "    accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
    "    print(f'Valid Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f1982-6094-48f2-8da0-5719cecde079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
